/**
 * WebAudio-Modem Vue3 Demo
 * 
 * Vue3 Composition APIã‚’ä½¿ç”¨ã—ãŸãƒ†ã‚­ã‚¹ãƒˆãƒ»ç”»åƒé€å—ä¿¡ãƒ‡ãƒ¢
 */

import { createApp, ref, reactive, toRaw, computed, onMounted, nextTick } from 'https://unpkg.com/vue@3/dist/vue.esm-browser.js';
import { WebAudioDataChannel } from '../src/webaudio/webaudio-data-channel.js';
import { DEFAULT_FSK_CONFIG } from '../src/modems/fsk.js';
import { XModemTransport } from '../src/transports/xmodem/xmodem.js';


const app = createApp({
  setup() {
    // ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
    const audioContext = ref(null);
    const senderDataChannel = ref(null);
    const receiverDataChannel = ref(null);
    const senderTransport = ref(null);
    const receiverTransport = ref(null);
    
    // Analyser nodes for visualization
    let outputGain = null;
    let inputAnalyser = null;
    
    // Canvas references
    const visualizerCanvas = ref(null);
    
    // Log content refs
    const sendLogContent = ref(null);
    const receiveLogContent = ref(null);
    
    // UIçŠ¶æ…‹
    const systemReady = ref(false);
    const isSending = ref(false);
    const showDebug = ref(false);
    const showVisualization = ref(true);
    const sendDataType = ref('text');
    const inputText = ref('Hello World');
    const selectedImage = ref(null);
    const sampleImageSelection = ref('');
    
    // Reactiveè¨­å®šç®¡ç†
    const fskConfig = reactive({
      ...DEFAULT_FSK_CONFIG,
      baudRate: 1200,
      // sampleRateã¯åˆæœŸåŒ–æ™‚ã«è¨­å®š
    });
    
    const xmodemConfig = reactive({
      timeoutMs: 3000,
      maxRetries: 5,
      maxPayloadSize: 255
    });
    
    // AbortControllerç®¡ç†
    const sendAbortController = ref(null);
    const receiveAbortController = ref(null);
    
    // ãƒã‚¤ã‚¯æ¨©é™ã¨å…¥åŠ›ã‚½ãƒ¼ã‚¹ç®¡ç†
    const microphonePermission = ref(false);
    const microphoneStream = ref(null);
    const inputSource = ref('loopback'); // 'loopback' | 'microphone'
    
    // ã‚µãƒ³ãƒ—ãƒ«ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«å®šç¾©
    const sampleImages = ref([
      { value: '', name: 'Custom file...', description: 'Upload your own file' },
      { value: 'jpg-interlaced.jpg', name: 'JPEG progressive (5.7K)', description: 'Progressive JPEG image' },
      { value: 'png-8.png', name: 'PNG 8-bit (9.5K)', description: '8-bit PNG image' },
      { value: 'png-interlaced.png', name: 'PNG Interlaced (12K)', description: 'Interlaced PNG image' },
      { value: 'webp.webp', name: 'WebP not progressive (3.8K)', description: 'WebP image' }
    ]);
    const sendLog = ref('');
    const receiveLog = ref('');
    
    // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç®¡ç†
    const systemStatus = reactive({ message: 'Click Initialize to start', type: 'info' });
    const sendStatus = reactive({ message: 'Initialize system first', type: 'info' });
    const receiveStatus = reactive({ message: 'Initialize system first', type: 'info' });
    
    // å—ä¿¡ãƒ‡ãƒ¼ã‚¿
    const receivedData = ref([]);
    
    // å—ä¿¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ï¼ˆçµ±ä¸€ï¼‰
    const receivingSession = ref({
      active: false,          // ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã®çŠ¶æ…‹
      currentTransfer: false, // ç¾åœ¨ã®è»¢é€ä¸­ã‹ã©ã†ã‹
      fragments: [],          // å—ä¿¡ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆå±¥æ­´
      totalReceived: 0,       // ç·å—ä¿¡ãƒã‚¤ãƒˆæ•°
      startTime: null,        // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚åˆ»
      bytesPerSecond: 0,      // å—ä¿¡ãƒ¬ãƒ¼ãƒˆ
      
      // ç¾åœ¨ã®è»¢é€ãƒ‡ãƒ¼ã‚¿
      currentTransferData: {
        fragments: [],        // ç¾åœ¨ã®è»¢é€ã®ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆ
        totalSize: 0,         // ç¾åœ¨ã®è»¢é€ã®ã‚µã‚¤ã‚º
        dataType: null,       // 'text' | 'image' | null
        previewUrl: null      // ç”»åƒãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼URLï¼ˆç”»åƒã®å ´åˆï¼‰
      }
    });
    
    // ãƒ‡ãƒãƒƒã‚°æƒ…å ±
    const senderDebugInfo = ref('No debug info');
    const receiverDebugInfo = ref('No debug info');
    
    // Computed properties
    const canSend = computed(() => {
      if (!systemReady.value || isSending.value) return false;
      if (sendDataType.value === 'text') return inputText.value.trim().length > 0;
      if (sendDataType.value === 'image') return selectedImage.value !== null;
      return false;
    });
    
    const canSendWithMic = computed(() => {
      // ãƒ«ãƒ¼ãƒ—ãƒãƒƒã‚¯æ™‚ã¯é€ä¿¡ä¸è¦ï¼ˆtestLoopbackã®ã¿ï¼‰
      if (inputSource.value === 'loopback') return false;
      return canSend.value && microphonePermission.value;
    });
    
    const canReceiveWithMic = computed(() => {
      // ãƒ«ãƒ¼ãƒ—ãƒãƒƒã‚¯æ™‚ã¯å—ä¿¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¸è¦ï¼ˆtestLoopbackã®ã¿ï¼‰
      if (inputSource.value === 'loopback') return false;
      return systemReady.value && microphonePermission.value;
    });
    
    // ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºè¨ˆç®—
    const textDataSize = computed(() => {
      if (inputText.value.trim()) {
        return new TextEncoder().encode(inputText.value).length;
      }
      return 0;
    });
    
    // Visualization variables
    let animationId = null;
    let inputWaveformData = null;
    
    // ãƒ­ã‚°å‡ºåŠ›
    const log = (message) => {
      logSend(message);
      logReceive(message);
    };
    
    // é€ä¿¡ãƒ­ã‚°å‡ºåŠ›
    const logSend = (message) => {
      const timestamp = new Date().toLocaleTimeString();
      const logEntry = `[${timestamp}] ${message}`;
      sendLog.value += logEntry + '\n';
      console.log(`[SEND] ${logEntry}`);
      
      // Auto-scroll to bottom
      nextTick(() => {
        if (sendLogContent.value) {
          sendLogContent.value.scrollTop = sendLogContent.value.scrollHeight;
        }
      });
    };
    
    // å—ä¿¡ãƒ­ã‚°å‡ºåŠ›
    const logReceive = (message) => {
      const timestamp = new Date().toLocaleTimeString();
      const logEntry = `[${timestamp}] ${message}`;
      receiveLog.value += logEntry + '\n';
      console.log(`[RECEIVE] ${logEntry}`);
      
      // Auto-scroll to bottom
      nextTick(() => {
        if (receiveLogContent.value) {
          receiveLogContent.value.scrollTop = receiveLogContent.value.scrollHeight;
        }
      });
    };
    
    // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°
    const updateStatus = (statusObj, message, type = 'info') => {
      statusObj.message = message;
      statusObj.type = type;
    };
    
    // ãƒ‡ãƒ¼ã‚¿æ¯”è¼ƒæ©Ÿèƒ½
    const getComparisonResult = (receivedDataItem) => {
      if (receivedDataItem.type === 'text') {
        const originalText = inputText.value.trim();
        const receivedText = receivedDataItem.content;
        
        if (originalText === receivedText) {
          return 'âœ… Perfect Match';
        } else {
          return `âŒ Mismatch (expected: "${originalText}")`;
        }
      } else if (receivedDataItem.type === 'image' && selectedImage.value) {
        // ç”»åƒã®å ´åˆã¯ã‚µã‚¤ã‚ºæ¯”è¼ƒï¼ˆç°¡æ˜“çš„ãªæ¯”è¼ƒï¼‰
        const originalSize = selectedImage.value.size;
        
        // Blob URLã‹ã‚‰å®Ÿéš›ã®ã‚µã‚¤ã‚ºã‚’å–å¾—ã™ã‚‹ã®ã¯å›°é›£ãªã®ã§ã€ç°¡æ˜“çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«åã§æ¯”è¼ƒ
        if (selectedImage.value.name && receivedDataItem.content) {
          return 'âœ… Image received (size comparison not available for blob URLs)';
        } else {
          return 'âŒ Image comparison failed';
        }
      }
      
      return 'â„¹ï¸ Unable to compare';
    };
    
    // ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    const initializeSystem = async () => {
      try {
        logSend('Initializing audio system...');
        logReceive(systemStatus, 'Initializing...', 'info');
        
        // AudioContextä½œæˆ
        audioContext.value = new AudioContext();
        log(`AudioContext created: ${audioContext.value.sampleRate}Hz`);
        outputGain = audioContext.value.createGain();
        outputGain.gain.value = 0.5; // åˆæœŸã‚²ã‚¤ãƒ³å€¤ 
        outputGain.connect(audioContext.value.destination);
        
        // AudioContextã®å†é–‹
        if (audioContext.value.state === 'suspended') {
          await audioContext.value.resume();
          log('AudioContext resumed');
        }
        
        // AudioWorkletãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¿½åŠ 
        await WebAudioDataChannel.addModule(audioContext.value, '../src/webaudio/processors/fsk-processor.js');
        log('FSK processor module loaded');
        
        // ãƒ‡ãƒ¼ã‚¿ãƒãƒ£ãƒãƒ«ä½œæˆ
        senderDataChannel.value = new WebAudioDataChannel(audioContext.value, 'fsk-processor', {
          processorOptions: { name: 'sender' }
        });
        receiverDataChannel.value = new WebAudioDataChannel(audioContext.value, 'fsk-processor', {
          processorOptions: { name: 'receiver' }
        });
        log('AudioWorkletNodes created');
        
        // Analyser nodesä½œæˆ
        inputAnalyser = audioContext.value.createAnalyser();
        inputAnalyser.fftSize = 2048;
        
        // reactiveè¨­å®šã«sampleRateã‚’è¨­å®š
        fskConfig.sampleRate = audioContext.value.sampleRate;
        
        // XModemãƒˆãƒ©ãƒ³ã‚¹ãƒãƒ¼ãƒˆä½œæˆï¼ˆè¨­å®šã¯ setupSender/setupReceiver ã§è¡Œã†ï¼‰
        senderTransport.value = new XModemTransport(senderDataChannel.value);
        receiverTransport.value = new XModemTransport(receiverDataChannel.value);
        
        log('Transports created successfully - configuration will be applied per operation');
        
        systemReady.value = true;
        updateStatus(systemStatus, 'System initialized âœ“ Try loopback test first!', 'success');
        updateStatus(sendStatus, 'Try loopback test first (no microphone needed)', 'info');
        updateStatus(receiveStatus, 'Try loopback test first (no microphone needed)', 'info');
        log('System initialization complete');
        
        // ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®å®šæœŸæ›´æ–°é–‹å§‹
        startDebugUpdates();
        
        // å¯è¦–åŒ–é–‹å§‹
        startVisualization();
        
        setupConnection('loopback'); // åˆæœŸã¯ãƒ«ãƒ¼ãƒ—ãƒãƒƒã‚¯æ¥ç¶š
      } catch (error) {
        const errorMsg = `Initialization failed: ${error.message}`;
        console.error(errorMsg, error);
        log(errorMsg);
        updateStatus(systemStatus, errorMsg, 'error');
        updateStatus(sendStatus, 'System initialization required', 'error');
        updateStatus(receiveStatus, 'System initialization required', 'error');
      }
    };
    
    // ãƒã‚¤ã‚¯æ¨©é™è¦æ±‚
    const requestMicrophonePermission = async () => {
      try {
        log('Requesting microphone permission...');
        updateStatus(systemStatus, 'Requesting microphone access...', 'info');
        
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: audioContext.value.sampleRate,
            channelCount: 1,
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false
          }
        });
        
        microphoneStream.value = stream;
        microphonePermission.value = true;
        toggleInputSource();
        
        log(`Microphone permission granted: ${audioContext.value.sampleRate}Hz, 1 channel`);
        updateStatus(systemStatus, 'Microphone ready âœ“ You can now use Send/Receive!', 'success');
        updateStatus(sendStatus, 'Ready to send with microphone', 'success');
        updateStatus(receiveStatus, 'Ready to receive with microphone', 'success');
        
      } catch (error) {
        const errorMsg = `Microphone access denied: ${error.message}`;
        console.error(errorMsg, error);
        log(errorMsg);
        updateStatus(systemStatus, errorMsg, 'error');
        updateStatus(sendStatus, 'Microphone required for Send', 'error');
        updateStatus(receiveStatus, 'Microphone required for Receive', 'error');
      }
    };
    
    // å…¥åŠ›ã‚½ãƒ¼ã‚¹åˆ‡ã‚Šæ›¿ãˆ
    const toggleInputSource = () => {
      if (inputSource.value === 'loopback') {
        inputSource.value = 'microphone';
        log('Switched to microphone input mode');
        updateStatus(systemStatus, 'Using microphone input', 'info');
      } else {
        inputSource.value = 'loopback';
        log('Switched to loopback mode');
        updateStatus(systemStatus, 'Using loopback mode', 'info');
      }
      setupConnection(inputSource.value);
    };
    
    // ãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆï¼ˆæ¨©é™å–å¾—ã‚‚å«ã‚€ï¼‰
    const toggleMicrophoneMode = async () => {
      if (!microphonePermission.value) {
        // ãƒã‚¤ã‚¯æ¨©é™ãŒãªã„å ´åˆã¯æ¨©é™ã‚’å–å¾—
        await requestMicrophonePermission();
      } else {
        // ãƒã‚¤ã‚¯æ¨©é™ãŒã‚ã‚‹å ´åˆã¯å…¥åŠ›ã‚½ãƒ¼ã‚¹ã‚’åˆ‡ã‚Šæ›¿ãˆ
        toggleInputSource();
      }
    };
    
    // ===== ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° =====
    
    // ãƒ‡ãƒ¼ã‚¿æº–å‚™
    const prepareDataForSending = () => {
      let data;
      let description;
      
      if (sendDataType.value === 'text') {
        const text = inputText.value.trim();
        if (!text) {
          throw new Error('Please enter text to send');
        }
        data = new TextEncoder().encode(text);
        description = `text: "${text}"`;
      } else if (sendDataType.value === 'image' && selectedImage.value) {
        data = selectedImage.value.data;
        description = `image: ${selectedImage.value.name} (${selectedImage.value.size} bytes)`;
      } else {
        throw new Error('Please select data to send');
      }
      
      return { data, description };
    };
    
    // Sender transportæº–å‚™
    const setupSender = async () => {
      await senderDataChannel.value.reset();
      await senderTransport.value.reset();
      logSend('Sender transport reset to IDLE state');
      
      // FSKè¨­å®šã‚’DataChannelã«é©ç”¨
      await senderDataChannel.value.configure(toRaw(fskConfig));
      logSend(`FSK configured: ${fskConfig.baudRate}bps, ${fskConfig.markFrequency}/${fskConfig.spaceFrequency}Hz`);
      
      // XModemè¨­å®šã‚’Transportã«é©ç”¨
      await senderTransport.value.configure({ ...toRaw(xmodemConfig), timeoutMs: xmodemConfig.timeoutMs * xmodemConfig.maxRetries });
      logSend(`XModem configured: timeout=${xmodemConfig.timeoutMs}ms, maxRetries=${xmodemConfig.maxRetries}`);
    };
    
    // Receiver transportæº–å‚™
    const setupReceiver = async () => {
      console.log('Setting up receiver transport...');
      await receiverDataChannel.value.reset();
      logReceive('Receiver transport reset to IDLE state');
      await receiverTransport.value.reset();
      
      // FSKè¨­å®šã‚’DataChannelã«é©ç”¨
      await receiverDataChannel.value.configure(toRaw(fskConfig));
      logReceive(`FSK configured: ${fskConfig.baudRate}bps, ${fskConfig.markFrequency}/${fskConfig.spaceFrequency}Hz`);
      
      // XModemè¨­å®šã‚’Transportã«é©ç”¨
      await receiverTransport.value.configure(toRaw(xmodemConfig));
      logReceive(`XModem configured: timeout=${xmodemConfig.timeoutMs}ms, maxRetries=${xmodemConfig.maxRetries}`);
    };
    
    // ç›¸äº’æ¥ç¶šè¨­å®š
    const setupConnection = (mode) => {
      // æ—¢å­˜ã®æ¥ç¶šã‚’ã‚¯ãƒªã‚¢
      senderDataChannel.value.disconnect();
      receiverDataChannel.value.disconnect();
      inputAnalyser.disconnect();

      if (mode === 'loopback') {
        // ãƒ«ãƒ¼ãƒ—ãƒãƒƒã‚¯æ¥ç¶š: sender âŸ· hub âŸ· receiver
        const hub = audioContext.value.createGain();
        hub.gain.value = 1.0;
        senderDataChannel.value.connect(hub);
        receiverDataChannel.value.connect(hub);
        hub.connect(outputGain);
        hub.connect(senderDataChannel.value);
        hub.connect(receiverDataChannel.value);
        hub.connect(inputAnalyser);
        log('Connected: sender âŸ· receiver (internal loopback)');
      } else if (mode === 'microphone') {
        // ãƒã‚¤ã‚¯æ¥ç¶š: mic â†’ sender/receiver + sender/receiver â†’ audio
        if (!microphoneStream.value) {
          throw new Error('Microphone not available');
        }
        
        const source = audioContext.value.createMediaStreamSource(microphoneStream.value);
        source.connect(senderDataChannel.value);
        source.connect(receiverDataChannel.value);
        senderDataChannel.value.connect(outputGain);
        receiverDataChannel.value.connect(outputGain);
        source.connect(inputAnalyser);
        log('Connected: microphone â†’ sender/receiver â†’ audio output');
      }
    };
    
    // ãƒ‡ãƒ¼ã‚¿é€ä¿¡
    const sendData = async () => {
      if (!canSendWithMic.value || isSending.value) {
        updateStatus(sendStatus, 'System not ready or microphone required', 'error');
        return;
      }
      
      try {
        const { data, description } = prepareDataForSending();
        
        isSending.value = true;
        logSend(`Sending ${description}`);
        updateStatus(sendStatus, 'Preparing XModem transmission...', 'info');
        
        // AbortControllerã‚’ä½œæˆ
        sendAbortController.value = new AbortController();
        
        // Transportæº–å‚™ã¨æ¥ç¶šè¨­å®š
        await setupSender();
        
        logSend(`Sending ${data.length} bytes via XModem protocol`);
        const modeIcon = inputSource.value === 'microphone' ? 'ğŸ¤' : 'ğŸ”„';
        updateStatus(sendStatus, `${modeIcon} Sending via XModem...`, 'info');
        
        await senderTransport.value.sendData(data, { signal: sendAbortController.value.signal });
        
        updateStatus(sendStatus, `âœ“ XModem send completed: ${description}`, 'success');
        logSend('XModem transmission completed successfully');
        
      } catch (error) {
        let errorMsg = `XModem send failed: ${error.message}`;
        
        // ãƒ‡ãƒ¼ã‚¿æº–å‚™æ®µéšã®ã‚¨ãƒ©ãƒ¼  
        if (error.message.includes('Please enter text') || error.message.includes('Please select data')) {
          errorMsg = error.message;
        } else if (error.message.includes('Transport busy')) {
          errorMsg = 'Sender is busy. Please wait and try again.';
          logSend('Sender transport is currently busy');
        } else if (error.message.includes('timeout')) {
          errorMsg = 'Send timeout. No receiver found or connection failed.';
          logSend('XModem send timed out - no receiver response');
        } else if (error.message.includes('Microphone not available')) {
          errorMsg = 'Microphone required. Click "Enable Microphone" first.';
          logSend('Microphone not available for sending');
        }
        
        logSend(errorMsg);
        updateStatus(sendStatus, errorMsg, 'error');
      } finally {
        isSending.value = false;
        sendAbortController.value = null;
      }
    };
    
    // é€ä¿¡åœæ­¢
    const stopSending = () => {
      if (!isSending.value) return;
      
      // AbortControllerã§é€ä¿¡ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
      if (sendAbortController.value) {
        sendAbortController.value.abort();
        logSend('Send operation aborted');
      }
      
      isSending.value = false;
      
      // æ¥ç¶šã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ è‡ªä½“ã¯ä¿æŒï¼‰
      if (senderDataChannel.value) {
        logSend('Disconnected sender and reset connections');
      }
      
      updateStatus(sendStatus, 'Sending stopped', 'info');
      logSend('XModem sending stopped');
    };
    
    // XModemãƒ«ãƒ¼ãƒ—ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    const testXModemLoopback = async () => {
      if (!systemReady.value) {
        updateStatus(systemStatus, 'System not initialized', 'error');
        return;
      }
      
      try {
        const { data, description } = prepareDataForSending();
        
        log(`Starting XModem loopback test with: ${description}`);
        updateStatus(systemStatus, 'Running XModem loopback test...', 'info');
        
        // AbortControllerã‚’ä½œæˆ
        sendAbortController.value = new AbortController();
        receiveAbortController.value = new AbortController();
        
        // Transportæº–å‚™ã¨æ¥ç¶šè¨­å®š
        await setupSender();
        await setupReceiver();
        setupConnection('loopback');
        
        log(`Testing ${data.length} bytes via XModem protocol`);

        receiverTransport.value.on('fragmentReceived', onFragmentReceived);
        
        try {
          // ãƒ«ãƒ¼ãƒ—ãƒãƒƒã‚¯ç”¨ã®ä¸€æ™‚çš„ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
          receivingSession.value.active = true;
          resetReceivingSession();
          receivingSession.value.active = true; // resetReceivingSessionãŒãƒªã‚»ãƒƒãƒˆã™ã‚‹ã®ã§å†è¨­å®š
          
          // é€å—ä¿¡é–‹å§‹
          logSend('Starting sender...');
          const sendPromise = senderTransport.value.sendData(data, { signal: sendAbortController.value.signal });
          
          await new Promise(resolve => setTimeout(resolve, 500));
          
          logReceive('Starting receiver...');
          const receivePromise = receiverTransport.value.receiveData({ signal: receiveAbortController.value.signal });
          
          const [_, receivedData] = await Promise.all([sendPromise, receivePromise]);
          
          // ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ã‚’å‰Šé™¤
          receiverTransport.value.off('fragmentReceived', onFragmentReceived);
          
          // ãƒ«ãƒ¼ãƒ—ãƒãƒƒã‚¯ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
          receivingSession.value.active = false;
        
          // çµæœå‡¦ç†
          if (sendDataType.value === 'text') {
            const receivedText = new TextDecoder().decode(receivedData);
            const originalText = inputText.value.trim();
            logReceive(`XModem loopback result: "${receivedText}"`);

            addReceivedData('text', receivedText);
            
            if (receivedText === originalText) {
              updateStatus(systemStatus, 'âœ“ Perfect XModem loopback!', 'success');
              logReceive('XModem loopback test: PASSED - Perfect match');
            } else {
              updateStatus(systemStatus, `âš  Partial match: "${receivedText}"`, 'info');
              logReceive(`XModem loopback test: PARTIAL - Expected: "${originalText}", Got: "${receivedText}"`);
            }
          } else {
            // ç”»åƒã®å ´åˆ
            const blob = new Blob([receivedData], { type: selectedImage.value.type });
            const url = URL.createObjectURL(blob);
            addReceivedData('image', url);
            
            if (receivedData.length === data.length) {
              updateStatus(systemStatus, 'âœ“ Perfect XModem image loopback!', 'success');
              logReceive('XModem image loopback test: PASSED - Size match');
            } else {
              updateStatus(systemStatus, `âš  Size mismatch: expected ${data.length}, got ${receivedData.length}`, 'info');
              logReceive(`XModem image loopback test: PARTIAL - Size mismatch`);
            }
          }
        } catch (loopbackError) {
          // ãƒªã‚¹ãƒŠãƒ¼ã‚’å¿…ãšå‰Šé™¤
          receiverTransport.value.off('fragmentReceived', onFragmentReceived);
          receivingSession.value.active = false;
          throw loopbackError;
        } finally {
          // AbortControllerã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
          sendAbortController.value = null;
          receiveAbortController.value = null;
        }
        
      } catch (error) {
        let errorMsg = `XModem loopback test failed: ${error.message}`;
        
        // ãƒ‡ãƒ¼ã‚¿æº–å‚™æ®µéšã®ã‚¨ãƒ©ãƒ¼
        if (error.message.includes('Please enter text') || error.message.includes('Please select data')) {
          errorMsg = error.message.replace('send', 'test');
        }
        
        console.error(errorMsg, error);
        log(errorMsg);
        updateStatus(systemStatus, errorMsg, 'error');
        
        // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ãƒªã‚¹ãƒŠãƒ¼ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try {
          receiverTransport.value.off('fragmentReceived', onFragmentReceived);
        } catch (cleanupError) {
          // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
        }
        
        // AbortControllerã‚‚ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        sendAbortController.value = null;
        receiveAbortController.value = null;
      }
    };
    
    // å—ä¿¡ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
    const addReceivedData = (type, content) => {
      receivedData.value.push({
        type,
        content,
        timestamp: new Date().toLocaleTimeString()
      });
    };
    
    // ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆå—ä¿¡ãƒªã‚¹ãƒŠãƒ¼ï¼ˆçµ±ä¸€ï¼‰
    const onFragmentReceived = (event) => {
      console.log('Fragment received:', event.data);
      const data = event.data;
      const now = Date.now();
      const session = receivingSession.value;
      
      // ã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒéã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚‰ç„¡è¦–
      if (!session.active) return;
      
      // è»¢é€é–‹å§‹æ™‚ã®åˆæœŸåŒ–
      if (!session.currentTransfer) {
        session.currentTransfer = true;
        session.startTime = now;
        
        // ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥åˆ¤å®š
        const dataType = detectDataType(data.fragment);
        session.currentTransferData.dataType = dataType;
        session.currentTransferData.fragments = [];
        session.currentTransferData.totalSize = 0;
        
        if (dataType === 'image') {
          logReceive('ğŸ–¼ï¸ Image transfer started');
        } else {
          logReceive('ğŸ“ Text transfer started');
        }
      }
      
      // ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆå±¥æ­´ã«è¿½åŠ 
      session.fragments.push({
        seqNum: data.seqNum,
        size: data.fragment.length,
        timestamp: new Date(data.timestamp).toLocaleTimeString(),
        data: data.fragment
      });
      
      // ç¾åœ¨ã®è»¢é€ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
      session.currentTransferData.fragments.push(data.fragment);
      session.currentTransferData.totalSize += data.fragment.length;
      session.totalReceived = data.totalBytesReceived;
      
      // å—ä¿¡ãƒ¬ãƒ¼ãƒˆè¨ˆç®—
      const elapsedMs = now - session.startTime;
      session.bytesPerSecond = elapsedMs > 0 ? Math.round((data.totalBytesReceived * 1000) / elapsedMs) : 0;
      
      // ç”»åƒã®å ´åˆã¯ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ›´æ–°
      if (session.currentTransferData.dataType === 'image') {
        updateImagePreview();
        const isLoopback = inputSource.value === 'loopback';
        const prefix = isLoopback ? 'ğŸ”„' : 'ğŸ–¼ï¸';
        logReceive(`${prefix} Image fragment #${data.seqNum}: ${data.fragment.length}B (total: ${session.currentTransferData.totalSize}B)`);

        if (isLoopback) {
          updateStatus(systemStatus, `${prefix} Fragment #${data.seqNum}: ${data.fragment.length}B (${data.totalBytesReceived}B)`, 'info');
        } else {
          updateStatus(receiveStatus, `${prefix} Fragment #${data.seqNum}: ${data.fragment.length}B (${data.totalBytesReceived}B @ ${session.bytesPerSecond}B/s)`, 'info');
        }
      } else {
        const isLoopback = inputSource.value === 'loopback';
        const prefix = isLoopback ? 'ğŸ”„' : 'ğŸ“¦';
        logReceive(`${prefix} Fragment #${data.seqNum}: ${data.fragment.length}B, total: ${data.totalBytesReceived}B (${session.bytesPerSecond}B/s)`);

        if (isTextData(data.fragment)) {
          const partialText = new TextDecoder().decode(data.fragment);
          if (isLoopback) {
            updateStatus(systemStatus, `${prefix} Fragment #${data.seqNum}: "${partialText}"`, 'info');
          } else {
            updateStatus(receiveStatus, `${prefix} Fragment #${data.seqNum}: "${partialText}" (${data.totalBytesReceived}B @ ${session.bytesPerSecond}B/s)`, 'info');
          }
        } else {
          if (isLoopback) {
            updateStatus(systemStatus, `${prefix} Fragment #${data.seqNum}: ${data.fragment.length}B`, 'info');
          } else {
            updateStatus(receiveStatus, `${prefix} Fragment #${data.seqNum}: ${data.fragment.length}B (${data.totalBytesReceived}B @ ${session.bytesPerSecond}B/s)`, 'info');
          }
        }
      }
    };
    
    // å—ä¿¡ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ï¼ˆãƒã‚¤ã‚¯ãƒ­ãƒ•ã‚©ãƒ³ãƒ¢ãƒ¼ãƒ‰ã®ã¿ï¼‰
    const startReceiving = async () => {
      if (receivingSession.value.active || !canReceiveWithMic.value) return;
      
      try {
        logReceive('Starting XModem receiving session...');
        updateStatus(receiveStatus, 'ğŸ¤ Starting reception session...', 'info');

        // ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
        resetReceivingSession();
        
        // AbortControllerã‚’ä½œæˆ
        receiveAbortController.value = new AbortController();
        
        // Transportæº–å‚™ã¨æ¥ç¶šè¨­å®š
        await setupReceiver();
        
        // ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆå—ä¿¡ãƒªã‚¹ãƒŠãƒ¼ã‚’ç™»éŒ²
        receiverTransport.value.on('fragmentReceived', onFragmentReceived);
        
        // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹
        receivingSession.value.active = true;
        updateStatus(receiveStatus, 'ğŸ¤ Ready for XModem transmission...', 'success');
        logReceive('Reception session started - ready for single transfers');
        
        // å˜ç™ºå—ä¿¡ã‚’é–‹å§‹
      
        logReceive('Waiting for single XModem transfer...');
        updateStatus(receiveStatus, 'ğŸ¤ Waiting for transmission...', 'info');
        
        const receivedBytes = await receiverTransport.value.receiveData({ 
          signal: receiveAbortController.value?.signal 
        });
        
        if (receivedBytes.length > 0 && receivingSession.value.active) {
          handleTransferComplete(receivedBytes);
        }
        
        receivingSession.value.active = false;
      } catch (error) {
        console.error('Failed to start reception session:', error);
        let errorMsg = `Failed to start reception session: ${error.message}`;
        
        if (error.message.includes('Microphone not available')) {
          errorMsg = 'Microphone required. Click "Enable Microphone" first.';
          logReceive('Microphone not available for receiving');
        }
        
        logReceive(errorMsg);
        updateStatus(receiveStatus, errorMsg, 'error');
        receivingSession.value.active = false;
        receiveAbortController.value = null;
      }
    };
    
    // è»¢é€å®Œäº†å‡¦ç†
    const handleTransferComplete = (receivedBytes) => {
      const session = receivingSession.value;
      
      if (session.currentTransferData.dataType === 'image') {
        logReceive(`âœ… Image transfer completed: ${receivedBytes.length} bytes`);
        
        const blob = new Blob([receivedBytes], { type: 'image/jpeg' });
        const finalUrl = URL.createObjectURL(blob);
        addReceivedData('image', finalUrl);
        
        updateStatus(receiveStatus, `âœ… Image received: ${receivedBytes.length} bytes`, 'success');
      } else {
        const text = new TextDecoder().decode(receivedBytes);
        logReceive(`âœ… Text transfer completed: "${text}"`);
        addReceivedData('text', text);
        updateStatus(receiveStatus, `âœ… Text received: "${text}"`, 'success');
      }
    };
    
    // ç¾åœ¨ã®è»¢é€ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯ç¶™ç¶šï¼‰
    const resetCurrentTransfer = () => {
      const session = receivingSession.value;
      session.currentTransfer = false;
      
      // å¤ã„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã‚’å‰Šé™¤
      if (session.currentTransferData.previewUrl) {
        URL.revokeObjectURL(session.currentTransferData.previewUrl);
      }
      
      session.currentTransferData = {
        fragments: [],
        totalSize: 0,
        dataType: null,
        previewUrl: null
      };
    };
    
    // å—ä¿¡ã‚»ãƒƒã‚·ãƒ§ãƒ³å…¨ä½“ã‚’ãƒªã‚»ãƒƒãƒˆ
    const resetReceivingSession = () => {
      const session = receivingSession.value;
      
      // å¤ã„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã‚’å‰Šé™¤
      if (session.currentTransferData.previewUrl) {
        URL.revokeObjectURL(session.currentTransferData.previewUrl);
      }
      
      receivingSession.value = {
        active: false,
        currentTransfer: false,
        fragments: [],
        totalReceived: 0,
        startTime: null,
        bytesPerSecond: 0,
        currentTransferData: {
          fragments: [],
          totalSize: 0,
          dataType: null,
          previewUrl: null
        }
      };
    };
    
    // å—ä¿¡åœæ­¢
    const stopReceiving = () => {
      if (!receivingSession.value.active) return;
      
      // AbortControllerã§å—ä¿¡ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
      if (receiveAbortController.value) {
        receiveAbortController.value.abort();
        logReceive('Receive operation aborted');
        receiveAbortController.value = null;
      }
      
      // ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†
      receivingSession.value.active = false;
      
      // ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆå—ä¿¡ãƒªã‚¹ãƒŠãƒ¼ã‚’å‰Šé™¤
      if (receiverTransport.value) {
        receiverTransport.value.off('fragmentReceived', onFragmentReceived);
      }
      
      // æ¥ç¶šã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ è‡ªä½“ã¯ä¿æŒï¼‰
      if (receiverDataChannel.value) {
        logReceive('Disconnected receiver and reset connections');
      }
      
      updateStatus(receiveStatus, 'Reception session stopped', 'info');
      logReceive('XModem reception session stopped');
    };
    
    // ãƒ‡ãƒ¼ã‚¿ãŒãƒ†ã‚­ã‚¹ãƒˆã‹ã©ã†ã‹ã®ç°¡æ˜“åˆ¤å®š
    const isTextData = (data) => {
      // ASCIIç¯„å›²å†…ã®æ–‡å­—ãŒå¤šã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã¨åˆ¤å®š
      let textChars = 0;
      const sampleSize = Math.min(100, data.length);
      
      for (let i = 0; i < sampleSize; i++) {
        const byte = data[i];
        if ((byte >= 32 && byte <= 126) || byte === 10 || byte === 13 || byte === 9) {
          textChars++;
        }
      }
      
      return textChars / sampleSize > 0.7;
    };
    
    // å—ä¿¡é–‹å§‹æ™‚ã®ãƒ‡ãƒ¼ã‚¿ç¨®åˆ¥ã‚’åˆ¤å®š
    const detectDataType = (firstFragment) => {
      // ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
      if (firstFragment.length >= 12) {
        const bytes = Array.from(firstFragment.slice(0, 12));
        console.log("Detecting data type from first fragment:", bytes);
        
        // JPEG: FF D8 FF
        if (bytes[0] === 0xFF && bytes[1] === 0xD8 && bytes[2] === 0xFF) {
          return 'image';
        }
        
        // PNG: 89 50 4E 47
        if (bytes[0] === 0x89 && bytes[1] === 0x50 && bytes[2] === 0x4E && bytes[3] === 0x47) {
          return 'image';
        }
        
        // GIF: 47 49 46
        if (bytes[0] === 0x47 && bytes[1] === 0x49 && bytes[2] === 0x46) {
          return 'image';
        }

        // BMP: 42 4D
        if (bytes[0] === 0x42 && bytes[1] === 0x4D) {
          return 'image';
        }

        // WebP: 52 49 46 46 __ __ __ __ 57 45 42 50
        if (bytes[0] === 0x52 && bytes[1] === 0x49 && bytes[2] === 0x46 && bytes[3] === 0x46) {
          return 'image';
        }
      }
      
      // ãƒ†ã‚­ã‚¹ãƒˆã‹ã©ã†ã‹ã‚’åˆ¤å®š
      return isTextData(firstFragment) ? 'text' : 'image';
    };
    
    // ç”»åƒãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµåˆã—ã¦ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æ›´æ–°
    const updateImagePreview = () => {
      const session = receivingSession.value;
      if (!session.currentTransfer || session.currentTransferData.fragments.length === 0) return;
      
      try {
        // ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµåˆ
        const fragments = session.currentTransferData.fragments;
        const totalSize = fragments.reduce((sum, frag) => sum + frag.length, 0);
        const combined = new Uint8Array(totalSize);
        let offset = 0;
        
        for (const fragment of fragments) {
          combined.set(fragment, offset);
          offset += fragment.length;
        }
        
        // Blobã‚’ä½œæˆã—ã¦ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨URLã‚’ç”Ÿæˆ
        const blob = new Blob([combined], { type: 'image/jpeg' });
        
        // å¤ã„URLã‚’å‰Šé™¤
        if (session.currentTransferData.previewUrl) {
          URL.revokeObjectURL(session.currentTransferData.previewUrl);
        }
        
        session.currentTransferData.previewUrl = URL.createObjectURL(blob);
        
      } catch (error) {
        logReceive(`Image preview update failed: ${error.message}`);
      }
    };
    
    // ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ
    const onImageSelect = async (event) => {
      const file = event.target.files[0];
      if (!file) {
        selectedImage.value = null;
        return;
      }
      
      if (!file.type.startsWith('image/')) {
        alert('Please select an image file');
        return;
      }
      
      try {
        const arrayBuffer = await file.arrayBuffer();
        const preview = URL.createObjectURL(file);
        
        selectedImage.value = {
          name: file.name,
          size: file.size,
          type: file.type,
          data: new Uint8Array(arrayBuffer),
          preview,
          source: 'custom'
        };
        
        // ã‚µãƒ³ãƒ—ãƒ«é¸æŠã‚’ãƒªã‚»ãƒƒãƒˆ
        sampleImageSelection.value = '';
        
        logSend(`Custom image selected: ${file.name} (${file.size} bytes)`);
      } catch (error) {
        logSend(`Failed to load custom image: ${error.message}`);
        selectedImage.value = null;
      }
    };
    
    // ã‚µãƒ³ãƒ—ãƒ«ç”»åƒé¸æŠ
    const onSampleImageSelect = async () => {
      if (!sampleImageSelection.value) {
        selectedImage.value = null;
        return;
      }
      
      try {
        const sampleFile = sampleImages.value.find(img => img.value === sampleImageSelection.value);
        if (!sampleFile || !sampleFile.value) return;
        
        // ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’fetchã§å–å¾—
        const response = await fetch(`./assets/sample-files/${sampleFile.value}`);
        if (!response.ok) {
          throw new Error(`HTTP ${response.status}: ${response.statusText}`);
        }
        
        const arrayBuffer = await response.arrayBuffer();
        const blob = new Blob([arrayBuffer]);
        const preview = URL.createObjectURL(blob);
        
        // ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’å–å¾—ã—ã¦MIMEã‚¿ã‚¤ãƒ—ã‚’æ¨å®š
        const extension = sampleFile.value.split('.').pop().toLowerCase();
        const mimeType = extension === 'png' ? 'image/png' : 'image/jpeg';
        
        selectedImage.value = {
          name: sampleFile.value,
          size: arrayBuffer.byteLength,
          type: mimeType,
          data: new Uint8Array(arrayBuffer),
          preview,
          source: 'sample'
        };
        
        logSend(`Sample image selected: ${sampleFile.name} (${arrayBuffer.byteLength} bytes)`);
      } catch (error) {
        logSend(`Failed to load sample image: ${error.message}`);
        selectedImage.value = null;
        sampleImageSelection.value = '';
      }
    };
    
    // ãƒ‡ãƒãƒƒã‚°åˆ‡ã‚Šæ›¿ãˆ
    const toggleDebug = () => {
      showDebug.value = !showDebug.value;
    };
    
    // æ³¢å½¢è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ
    const toggleVisualization = () => {
      showVisualization.value = !showVisualization.value;
    };
    
    // ãƒ­ã‚°ã‚¯ãƒªã‚¢
    const clearLogs = () => {
      sendLog.value = '';
      receiveLog.value = '';
      logSend('Logs cleared');
      logReceive('Logs cleared');
    };
    
    // ãƒ‡ãƒãƒƒã‚°æƒ…å ±æ›´æ–°é–‹å§‹
    const startDebugUpdates = () => {
      setInterval(async () => {
        if (showDebug.value && systemReady.value) {
          try {
            if (senderDataChannel.value) {
              const senderInfo = await senderDataChannel.value.getStatus();
              senderDebugInfo.value = JSON.stringify(senderInfo, null, 2);
            }
            if (receiverDataChannel.value) {
              const receiverInfo = await receiverDataChannel.value.getStatus();
              receiverDebugInfo.value = JSON.stringify(receiverInfo, null, 2);
            }
          } catch (error) {
            // ãƒ‡ãƒãƒƒã‚°æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
          }
        }
      }, 500);
    };
    
    // å¯è¦–åŒ–é–‹å§‹
    const startVisualization = () => {
      if (!inputAnalyser) return;
      
      const bufferLength = inputAnalyser.frequencyBinCount;
      inputWaveformData = new Uint8Array(bufferLength);
      
      const animate = () => {
        if (!systemReady.value || !showVisualization.value) {
          animationId = requestAnimationFrame(animate);
          return;
        }
        
        // å—ä¿¡è€…ï¼ˆå¾©èª¿å™¨å…¥åŠ›ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿å–å¾—ãƒ»è¡¨ç¤º
        inputAnalyser.getByteTimeDomainData(inputWaveformData);

        // çµ±åˆã•ã‚ŒãŸå¯è¦–åŒ–canvasã«æç”»
        drawUnifiedWaveform(visualizerCanvas.value, inputWaveformData);

        animationId = requestAnimationFrame(animate);
      };
      
      animate();
    };
    
    // çµ±åˆæ³¢å½¢æç”»
    const drawUnifiedWaveform = (canvas, data) => {
      if (!canvas || !data) return;
      
      const ctx = canvas.getContext('2d');
      const width = canvas.width;
      const height = canvas.height;
      
      // èƒŒæ™¯ã‚’ã‚¯ãƒªã‚¢
      ctx.fillStyle = '#000';
      ctx.fillRect(0, 0, width, height);
      
      // ã‚°ãƒªãƒƒãƒ‰ç·šã‚’æç”»
      ctx.strokeStyle = '#333';
      ctx.lineWidth = 1;
      ctx.beginPath();
      
      // æ°´å¹³ã‚°ãƒªãƒƒãƒ‰
      for (let i = 0; i <= 4; i++) {
        const y = (height / 4) * i;
        ctx.moveTo(0, y);
        ctx.lineTo(width, y);
      }
      
      // å‚ç›´ã‚°ãƒªãƒƒãƒ‰
      for (let i = 0; i <= 8; i++) {
        const x = (width / 8) * i;
        ctx.moveTo(x, 0);
        ctx.lineTo(x, height);
      }
      ctx.stroke();
      
      // æ³¢å½¢æç”»
      ctx.lineWidth = 2;
      ctx.strokeStyle = '#00ff88';
      ctx.beginPath();
      
      const sliceWidth = width / data.length;
      let x = 0;
      
      for (let i = 0; i < data.length; i++) {
        const v = (data[i] - 128) / 128.0; // -1 to 1ã®ç¯„å›²ã«æ­£è¦åŒ–
        const y = height / 2 + (v * height / 2);
        
        if (i === 0) {
          ctx.moveTo(x, y);
        } else {
          ctx.lineTo(x, y);
        }
        
        x += sliceWidth;
      }
      
      ctx.stroke();
      
      // ä¸­å¤®ç·š
      ctx.strokeStyle = '#666';
      ctx.lineWidth = 1;
      ctx.beginPath();
      ctx.moveTo(0, height / 2);
      ctx.lineTo(width, height / 2);
      ctx.stroke();
    };
    
    
    // å…¨ã‚¯ãƒªã‚¢
    const clearAll = () => {
      receivedData.value = [];
      
      // å—ä¿¡ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
      resetReceivingSession();
      
      log('All data and logs cleared');
    };
    
    // ãƒã‚¦ãƒ³ãƒˆæ™‚ã®å‡¦ç†
    onMounted(() => {
      log('WebAudio-Modem Demo loaded');
    });
    
    // ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç ´æ£„æ™‚ã®å‡¦ç†
    const cleanup = () => {
      if (animationId) {
        cancelAnimationFrame(animationId);
      }
      if (receivingSession.value.active) {
        stopReceiving();
      }
      if (isSending.value) {
        stopSending();
      }
      
      // ãƒã‚¤ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
      if (microphoneStream.value) {
        microphoneStream.value.getTracks().forEach(track => {
          track.stop();
          log(`Stopped microphone track: ${track.kind}`);
        });
        microphoneStream.value = null;
        microphonePermission.value = false;
      }
    };
    
    return {
      // State
      systemReady,
      isSending,
      showDebug,
      showVisualization,
      sendDataType,
      inputText,
      selectedImage,
      sampleImageSelection,
      sampleImages,
      sendLog,
      receiveLog,
      systemStatus,
      sendStatus,
      receiveStatus,
      receivedData,
      receivingSession,
      senderDebugInfo,
      receiverDebugInfo,
      
      // ãƒã‚¤ã‚¯æ¨©é™ã¨å…¥åŠ›ã‚½ãƒ¼ã‚¹
      microphonePermission,
      inputSource,
      
      // Reactiveè¨­å®š
      fskConfig,
      xmodemConfig,
      
      // Computed
      canSend,
      canSendWithMic,
      canReceiveWithMic,
      textDataSize,
      
      // Canvas refs
      visualizerCanvas,
      sendLogContent,
      receiveLogContent,
      
      // Methods
      initializeSystem,
      requestMicrophonePermission,
      toggleInputSource,
      toggleMicrophoneMode,
      sendData,
      stopSending,
      testXModemLoopback,
      startReceiving,
      stopReceiving,
      onImageSelect,
      onSampleImageSelect,
      toggleDebug,
      toggleVisualization,
      clearLogs,
      clearAll,
      getComparisonResult,
      cleanup
    };
  }
});

app.mount('#app');
